\chapter{Modelos de Distribución de Probabilidad}
\section{Distribuciones Discretas}
\subsection{Distribución de Bernoulli}
Si la probabilidad de que ocurra un evento $p$ y la probabilidad de que no ocurra es $q(q=1-p)$, entonces se dice que la \textbf{v.a.} discreta $X$ se distribuye según Bernoulli, cuya función de cuantía está dada por:
$$p(x)=f(x)=P(X=x)=
\begin{cases}
p^x\cdot (1-p)^{1-x} &; x=0;1 \\
0 &; \text{otro caso}
\end{cases}
$$
Y cuya función de distribución acumulada es:
$$
F(X)=P(X=x)=
\begin{cases}
0 &; x<0\\
q=1-p &; 0\leq x < 1\\
1 &; x\geq 1
\end{cases}
$$

$$
X \sim Ber(x;p)\Rightarrow 
\begin{cases}
E(x)=\mu = p \\
V(x)=\sigma^2 = p\cdot q \\
D(x) = \sigma = \sqrt{p\cdot q}
\end{cases}
$$
Conocida como prueba o ensayo de Bernoulli, es un experimento que solo tiene 2 resultados posibles, a los cuales se los llama:
\begin{itemize}
\item Éxito $(p)$
\item Fracaso $(q)$
\end{itemize}
\subsection{Distribución Binomial}
Una \textbf{v.a.} discreta $X$ tiene distribución lineal si su función de cuantía está dada por:
$$
f(x)=
\begin{cases}
\displaystyle\binom{n}{x} p^x \cdot q^{n-x} &; x=0,1,2,\ldots,n \\
0 &; \text{otro caso}
\end{cases}
$$
Donde:
\begin{itemize}
\item $p:$ Probabilidad de éxito.
\item $n:$ Número de ensayo.
\item $x:$ Número de éxitos.
\end{itemize}
Las Funciones de Distribución Acumulada Binomialmente está definida por:
$$
F(x)=P(X\leq x)=
\begin{cases}
0 &; x<0 \\
\displaystyle\sum_{k=0}^{[\![ x ]\!]}\displaystyle\binom{n}{k} p^k q^{n-k} &; 0\leq x < n \\
1 &; x\geq n
\end{cases}
$$
$$
X \sim b(x;n,p)\Rightarrow 
\begin{cases}
E(x)=\mu = n\cdot p \\
V(x)=\sigma^2 = n\cdot p \cdot q \\
D(x)=\sigma=\sqrt{n\cdot p\cdot q}
\end{cases}
$$

\subsubsection{Características de la Distribución Binomial}
\begin{enumerate}
\item Se realiza $n$ pruebas , cada una independiente.
\item $p$ es la probabilidad de éxito en cada prueba que ocurra en un evento y se mantiene constante a travez de las $n$ pruebas.
\item El experimento es con reposición (sustitución por reemplazo).
\item Se da el valor de la \textbf{v.a.} $X$. La variación de $x$ es desde 0 hasta $n$.

\end{enumerate}

\subsubsection{Observaciones}
$$f(x)=b(x;n,p) \hspace{1cm} n \text{ y } p \text{ son parámetros.}$$
\subsubsection{Manejo de la Tabla Binomial}
\begin{enumerate}
\item $\displaystyle\binom{p\leq 0.50}{n\leq 20}\Rightarrow
b(x;n,p)=B(x;n,p)-B(x-1;n,p)
$
\item $\displaystyle\binom{p>0.50}{n\geq 20}\Rightarrow 
\begin{cases}
\textbf{(i.) }b(x;n,p)= B(n-x;n,1-p)-B(n-x-1;n,1-p) \\
\textbf{(ii.) }b(x;n,p)=b(n-x;n,1-p) \text{ luego de usar \textbf{(i.)}} \\
\textbf{(iii.) } B(x;n,p) = 1 - B(n-x-1;n,1-p)
\end{cases}
$
\end{enumerate}
\subsection{Distribución de Poisson}
Una \textbf{v.a.} discreta $X$ tiene distribución de Poisson, si su función de cuantía está dada por:
$$
p(x)=f(x)=
\begin{cases}
\dfrac{e^{-\lambda}\cdot \lambda^x}{x!};& x=0,1,2,\ldots \\
0 ;& \text{otro caso}
\end{cases}
$$
Parámetro: $\lambda > 0$  \\$ { } $\\
La distribución de Poisson se obtiene de 2 maneras:
\begin{enumerate}
\item $\lim_{\substack{ n\to \infty \\ p\to 0 }} \displaystyle\binom{n}{x}\cdot p^x \cdot q^{n-x}\backsimeq \dfrac{e^{-\lambda}\cdot \lambda^x}{x!} \hspace{1cm} x=0,1,2,\ldots$
\item $p(x)=f(x)=\dfrac{e^{-\lambda\cdot t}(\lambda\cdot t)^x}{x!} \hspace{1cm} x=0,1,2,\ldots$
\end{enumerate}
donde $t$ es la cantidad de medida (intervalo de tiempo, longitud, área, etc...) La \textbf{F.D.A.} de Poisson está dada por:
$$
F(x)=
\begin{cases}
0 &; x<0 \\
\displaystyle\sum_{k=0}^{[\![ x ]\!]} \dfrac{e^{-\lambda}\cdot \lambda^x}{x!} &; x\geq 0
\end{cases}
$$
$$
X \sim Poisson(x;\lambda)\Rightarrow
\begin{cases}
E(x) = \mu = \lambda = n\cdot p \\
V(x) = \sigma^2 = n\cdot p \\
D(x) = \sigma = \sqrt{\lambda}

\end{cases}
$$
\subsection{Distribución Geométrica}
También llamada Distribución de Pascal, es un modelo útil para aquellos procesos en los que se repiten pruebas hasta llegar al éxito o a un resultado deseado y tiene interesantes aplicaciones en los muestreos realizados de esta manera. Su función de cuantía está dada por:
$$
p(x)=f(x)=q^{n-1}\cdot p
$$
También implica la existencia de una dicotomía de posibles resultados y la independencia de las pruebas entre sí.
\subsection{Distribución Hipergeométrica}
\subsection{Distribución Binomial Negativa}
\subsection{Distribución Multinomial}
\section{Distribuciones Continuas}
\subsection{Distribución Uniforme o Rectangular}
Se dice que una \textbf{v.a.} continua $X$ tiene distribución uniforme en el intervalo $[a,b]$, si su función de densidad está dada por:
$$
f(x) = 
\begin{cases}
\dfrac{1}{b-a} ;& a\leq x \leq b \\
0 ;& \text{en otro caso.}
\end{cases}
$$
Parámetros: $a,b$ \\$ { } $\\
La gráfica de esta función se muestra en la siguiente figura:
%PENDIENTE
La \textbf{F.D.A.} de $X$, distribuida uniformemente, está dada por:
$$
F(x)=P(X\leq x)=
\begin{cases}
0 ;& x<a \\
\displaystyle\int_{-\infty}^{x} \dfrac{1}{b-a} dx=\dfrac{x-a}{b-a} ;& a\leq x < b \\
1 ;& x\geq b
\end{cases}
$$ 
La gráfica de $F$ es:
%PENDIENTE
$$
X \sim U(x;a,b)\Rightarrow 
\begin{cases}
E(x)=\mu = \dfrac{a+b}{2} \\
V(x)=\sigma^2 = \dfrac{(b-a)^2}{12} \\
D(x)=\sigma = \dfrac{(b-a)\sqrt{3}}{6}
\end{cases}
$$
\subsection{Distribución Exponencial}
Sea $X$ una \textbf{v.a.} continua. Se dice que $X$ tiene distribución exponencial con el parámetro real $\lambda$, si su función de densidad está dada por:
$$
f(x)=
\begin{cases}
\lambda\cdot e^{-\lambda\cdot x} ,& x\geq 0 \\
0 ,& \text{en otro caso}
\end{cases}
$$
Parámetro: $\lambda>0$ \\${ }$\\
La gráfica de $f$, se muestra en la siguiente figura:
%
La \textbf{F.D.A.} de $X$, distribuida exponencialmente está dada por:
$$
F(x)=P(X\leq x)=
\begin{cases}
0, & x<0 \\
\displaystyle\int_{-\infty}^{x} \lambda\cdot e^{-\lambda\cdot x} dx ,& x\geq 0
\end{cases}
$$
La gráfica de $F$, es la siguiente:
%PENDIENTE
$$
X\sim exp(x;\lambda)\Rightarrow
\begin{cases}
E(x) = \mu = \frac{1}{\lambda} \\
V(x) = \sigma^2 = \frac{1}{\lambda^2} \\
D(x) = \sigma = \frac{1}{\lambda}
\end{cases}
$$
\subsubsection{Propiedad Amnésica}
$$P(X>5+t / x> s)=P(X>t)$$

%REALIZAR TABLA DE DATOS DE LAS DISTRIBUCIONES, NO OLVIDAR
\subsection{Distribución Normal}
Una \textbf{v.a.} continua $X$ tiene distribución normal con media $E(x)=\mu \in \mathbb{R}$ y varianza $V(x)=\sigma^2 >0$, si su función de densidad está dada por:
$$
f(x) = N(x;\mu,\sigma^2)=N(\mu,\sigma^2)=\dfrac{1}{\sigma \cdot \sqrt{2\pi}}e^{-\frac{1}{2}(\frac{x-\mu}{\sigma})}, x\in \mathbb{R}
$$
La gráfica de $f(x)$ es la siguiente:
%PENDIENTE
\subsubsection{Características de la Curva Normal}
\begin{enumerate}
\item $f'(x)=0\Leftrightarrow x=\mu$
\item $x<\mu \Rightarrow f'(x)>0;$ luego $f$ es creciente en $]-\infty,\mu]$
\item $x>\mu \Rightarrow f'(x)<0;$ luego $f$ es decreciente en $[\mu,+\infty[$
\item La curva tiene un máximo en $x=\mu$. (Moda en $\mu$)
\item $f''(x)=0 \Leftrightarrow x = \mu + \sigma$
\item Los puntos de inflexión están en: $x=\mu-\sigma$ y $x=\mu+\sigma$.
\item La curva de la distribución normal es simétrica respecto de $\mu$.
\item La media, mediana y moda son iguales (coinciden).
\item El área total bajo la curva normal y arriba del eje horizontal, es igual a 1.
\item La curva de la distribución normal se extiende $]-\infty,+\infty[$.
\end{enumerate}
\subsubsection{Distribución Normal Estándar}