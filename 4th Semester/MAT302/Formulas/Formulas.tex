\documentclass[10pt,letterpaper]{article}
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{subfiles}
\usepackage{enumitem}
\usepackage[affil-it]{authblk}
\usepackage{array}
\usepackage{tabularx}
\usepackage{multicol}
\usepackage{slashbox}
\usepackage{diagbox}
\usepackage{slashbox,multirow}
\usepackage{enumitem}
\usepackage{mathtools}
\usepackage{pstricks}
\usepackage{pgfplots}
\usepackage{enumitem}
\usepackage{tikz}
\usepackage{calc}
\usepackage{ifthen}
\usepackage{mathrsfs} %Contiene el Signo de Transformada de Laplace
\usepackage{empheq}
\usepackage{svg}
\usepackage{hyperref}
\usepackage[left=2cm,right=2cm,top=2cm,bottom=2cm]{geometry}
\author{Leonardo H. Añez Vladimirovna\\
\texttt{toborochi98@outlook.com}
}
\title{Fórmulas de Probabilidad y Estadística II \texttt{(MAT302)}\\{\normalsize Facultad de Ingeniería en Ciencias de la Computación y Telecomunicaciones}\\{\normalsize Universidad Autónoma Gabriel René Moreno}}
 \pgfplotsset{compat=1.16}
\begin{document}
\maketitle

\section{Variables Aleatorias}
\subsection{Definiciones}
\begin{multicols}{2}
\subsubsection{Discretas}
\begin{flushleft}
Notación:  $P(A),P(X=x),f(x)$.
\begin{enumerate}
\item $p(x)\geq 0 ; \forall x \in \mathbb{R}$
\item $\displaystyle\sum_{x_i\in Rec_x} p(x_i)=1$
\item $\displaystyle\sum_{i=1}^{n} p(x_i)=1$
\item $\displaystyle\sum_{i=1}^{\infty} p(x_i)=1$
\end{enumerate}
\end{flushleft}
\columnbreak
\subsubsection{Continuas}
\begin{flushleft}
Notación:  $F(x),P(X\leq x)$.
\begin{enumerate}
\item $f(x)\geq 0;\forall x \in \mathbb{R}$
\item $\displaystyle\int_{-\infty}^{+\infty} f(x)dx = 1$
\item $P(a\leq x \leq b) = \displaystyle\int_{a}^{b} f(x)dx=1$
\end{enumerate}
\end{flushleft}
\end{multicols}
\subsection{Propiedades}
\begin{multicols}{2}
\subsubsection{Discreta}
\begin{enumerate}
\item $0\leq F(x) \leq 1, \forall x\in \mathbb{R}$
\item $F(-\infty)=0$
\item $F(+\infty)=1$
\item $P(X\leq a)=F(a)$
\item $P(X>a)=1-P(X\leq a)=1-F(a)$
\item $P(X<a)=
\begin{cases}
F(a-1); a\in\mathbb{Z} \\
F( [\![ x ]\!] ) ; a \notin \mathbb{Z}
\end{cases}$
\item $P(X\leq -a)=1-P(x\leq a)=1-F(a)$
\item $P(a<x\leq b)=F(b)-F(a)$
\item $P(X\leq x\leq)=F(b)-F(a)+P(X=a)$
\item $P(a<x<b)=F(b)-F(a)-P(X=b)$
\item $P(X=x_i)=F(x_i)-F(x_{i-1})$
\end{enumerate}
\columnbreak
\subsubsection{Continua}
\begin{enumerate}
\item $0\leq F(x) \leq 1, \forall x\in \mathbb{R}$
\item $F(-\infty)=0$
\item $F(+\infty)=1$
\item $P(X\leq a)=P(X<a)=F(a)$
\item $P(X>a)=1-P(X\leq a)=1-F(a)$
\item $P(X\geq a)=1-P(X<a)=1-F(a)$
\item $P(X\leq -a)=1-P(X\leq a)=1-F(a)$
\item $P(a<X\leq b)=P(a\leq X\leq b)=P(a<X<b)=F(b)-F(a)$
\item $f(x)=\dfrac{dF(x)}{dx}$
\end{enumerate}
\end{multicols}
\pagebreak
\subsection{Esperanza}
\begin{multicols}{3}
\subsubsection{V.A.s Discretas}
$E(x)=\mu=\mu_x=\displaystyle\sum_x x\cdot p(x)$ \\ \vspace{0.05cm} \\
$X$ v.a. con función $f$: \\ \vspace{0.05cm} \\
$E(g(x))=\mu_{g(x)}=\displaystyle\sum_x g(x)\cdot f(x)$
\columnbreak
\subsubsection{V.A.s Continua}
$E(x)=\displaystyle\int_{-\infty}^{+\infty} xf(x) dx$\\ \vspace{0.05cm} \\
$X$ v.a. con función $f$: \\ \vspace{0.05cm} \\
$E(x)=\displaystyle\int_{-\infty}^{+\infty} g(x)\cdot f(x) dx$
\columnbreak
\subsubsection{Propiedades}
$\bigstar$ {\scriptsize $a$ y $b$ constantes.}
\begin{enumerate}
\item $E(a)=a$
\item $E(x\pm a)=E(x)\pm a$
\item $E(ax)=aE(x)$
\item $E(ax\pm b)=aE(x)\pm b$
\end{enumerate}
\end{multicols}



\subsection{Varianza}
\begin{multicols}{3}
\subsubsection{V.A.s Discretas}
\begin{align*}
V(x)=\sigma^2 &=  E(x-\mu)^2 \\
& = \displaystyle\sum_x (x-\mu)^2 f(x) 
\end{align*}
\columnbreak
\subsubsection{V.A.s Continua}
\begin{align*}
V(x)=\sigma^2 &=  E(x-\mu)^2 \\
& = \displaystyle\int_{-\infty}^{+\infty} (x-\mu)^2 f(x) dx
\end{align*}
\columnbreak
\subsubsection{Propiedades}
\begin{enumerate}
\item $V(x)\geq 0$
\item $V(a)=0$
\item $V(ax)=aV(x)$
\item $V(ax\pm b)=a^2 V(x)\pm b$
\item $V(x)=E(x^2)-[E(x)]^2$
\end{enumerate}
\end{multicols}
\subsection{Función de Probabilidad Conjunta}
\begin{multicols}{2}
\subsubsection{Función de Cuantía Conjunta (Discreta)}
\begin{enumerate}
\item $P(x,y)=P(X=x,Y=y)\geq 0$
\item $\displaystyle\sum_x \displaystyle\sum_y P(x,y)=1$
\item $P((x,y)\in A) = \sum_A \sum P(x,y)$
\end{enumerate}
\columnbreak
\subsubsection{Función de Densidad Conjunta (Continua)}
\begin{enumerate}
\item $f(x,y)\geq 0$
\item $\displaystyle\int_{-\infty}^{+\infty}\int_{-\infty}^{+\infty} f(x,y) dxdy = 1$
\item $P((x,y)\in A)=\displaystyle\int_A \int f(x,y) dxdy$
\end{enumerate}
\end{multicols}

\subsection{Distribuciones Marginales}
\begin{multicols}{2}
\subsubsection{Caso Discreto}
\begin{itemize}
\item \textbf{Distribución Marginal de }$X$:\\ \vspace{0.05cm} \\
$g(x)=\displaystyle\sum_y f(x,y)$
\item \textbf{Distribución Marginal de }$Y$:\\ \vspace{0.05cm} \\
$h(y)=\displaystyle\sum_x f(x,y)$
\end{itemize}
\columnbreak
\subsubsection{Caso Continuo}
\begin{itemize}
\item \textbf{Distribución Marginal de }$X$:\\ \vspace{0.05cm} \\
$g(x)=\displaystyle\int_{-\infty}^{+\infty} f(x,y)dy$
\item \textbf{Distribución Marginal de }$Y$:\\ \vspace{0.05cm} \\
$h(y)=\displaystyle\int_{-\infty}^{+\infty} f(x,y)dx$
\end{itemize}
\end{multicols}
\pagebreak
\subsection{Covarianza}

\begin{multicols}{2}
\subsubsection{Caso Discreto}
\begin{align*}
Cov(x,y)=\sigma_{xy}&=E((x-\mu_x)(y-\mu_y)) \\
&=\displaystyle\sum_x\sum_y (x-\mu_x)(y-\mu_y)f(x,y)
\end{align*}
\columnbreak
\subsubsection{Caso Continuo}
\begin{align*}
Cov(x,y)=\sigma_{xy}&=E((x-\mu_x)(y-\mu_y)) \\
&=\displaystyle\int_{-\infty}^{+\infty}\int_{-\infty}^{+\infty} (x-\mu_x)(y-\mu_y)f(x,y)dxdy
\end{align*}
\end{multicols}
\subsection{Resultados Importantes}
\begin{enumerate}
\item $E(x\pm y)=E(x)\pm E(y)$
\item $Cov(x,y)=E(x\cdot y)-E(x)\cdot E(y)$
\item $V(x\pm y)=V(x)+V(y)\pm 2Cov(x,y)$
\item $V(ax\pm by)=a^2V(x)+b^2V(y) \pm 2ab\cdot Cov(x,y)$
\item Si $x$ y $y$ son estadísticamente independientes:
\begin{enumerate}
\item $E(x,y)=E(x)\cdot E(y)$
\item $Cov(x,y)=0$
\item $V(x\pm y)=V(x)+V(y)$
\item $V(ax\pm by)=a^2V(x)+b^2V(y)$
\end{enumerate}
\item Si $x1,x2,x3,\ldots$ son variables aleatorias independientes 2 a 2:\\ \vspace{0.025cm} \\
$V\Bigg( \displaystyle\sum_{i=1}^{m} x_i \Bigg) = \displaystyle\sum_{i=1}^{m} V(x_i)$
\end{enumerate}

\section{Distribuciones}
\subsection{Distribuciones Discretas}
\subsubsection{Distribución de Bernoulli $(Ber)$}
\begin{multicols}{2}
\begin{itemize}
\item Función de Cuantía \\ \vspace{0.025cm} \\
$f(x)=p(x)=
\begin{cases}
p^x(1-p)^{1-x} &; x=0,1 \\
0 &; \text{otro caso}
\end{cases}$
\end{itemize}
\columnbreak
\begin{itemize}
\item Función Acumulada \\
$F(x)=P(X=x)=
\begin{cases}
0 &; x<0 \\
q=1-p &; 0 \leq x <1 \\
1 &; x\geq 1
\end{cases}$
\end{itemize}
\end{multicols}
$$
X\sim Ber(x;p)\Rightarrow 
\begin{cases}
E(x)=\mu = p \\
V(x)=\sigma^2 = p\cdot q \\
D(x)=\sigma=\sqrt{p\cdot q}
\end{cases}
$$
\subsubsection{Distribución Binomial $(b)$}
\begin{multicols}{2}
\begin{itemize}
\item Función de Cuantía \\ \vspace{0.025cm} \\
$f(x)=p(x)=
\begin{cases}
\binom{n}{x} p^x \cdot q^{n-x} &; x=0,1,2,\ldots ,n \\
0 &; \text{otro caso}
\end{cases}$
\end{itemize}
\columnbreak
\begin{itemize}
\item Función Acumulada \\
$F(x)=P(X=x)=
\begin{cases}
0 &; x<0 \\
\displaystyle\sum_{k=0}^{[\![ x ]\!]} \binom{n}{k}p^k q^{n-k} &; 0 \leq x <n \\
1 &; x\geq 1
\end{cases}$
\end{itemize}
\end{multicols}
$$
X\sim b(x;n,p)\Rightarrow 
\begin{cases}
E(x)=\mu = p \\
V(x)=\sigma^2 = npq\\
D(x)=\sigma=\sqrt{npq}
\end{cases}
$$
$\bigstar$ Manejo de la Tabla:
\begin{enumerate}
\item $\displaystyle\binom{p\leq 0.50}{n\leq 20} \Rightarrow b(x;n,p) = B(x;n,p)-B(x-1;n,p)$
\item $\displaystyle\binom{p> 0.50}{n\leq 20}\Rightarrow
\begin{cases}
\text{\textbf{(i) }} b(x;n,p) = B(n-x;n,1-p)-B(n-x-1;n,1-p) \\
\text{\textbf{(ii) }} b(x;n,p) = b(n-x,n,1-p) \text{ luego (i)}\\
\text{\textbf{(iii) }} B(x;n,p) = 1-B(n-x;n,1-p) 
\end{cases}$
\end{enumerate}
\subsubsection{Distribución de Poisson $(Poisson)$}
\begin{multicols}{2}
\begin{itemize}
\item Función de Cuantía \\ \vspace{0.025cm} \\
$f(x)=p(x)=
\begin{cases}
\dfrac{e^{-\lambda} \cdot \lambda^x}{x!} &; x=0,1,2,\ldots \\
0 &; \text{otro caso}
\end{cases}$
\end{itemize}
\columnbreak
\begin{itemize}
\item Función Acumulada \\
$F(x)=P(X=x)=
\begin{cases}
0 &; x<0 \\
\displaystyle\sum_{x=0}^{[\![ x ]\!]} \dfrac{e^{-\lambda} \cdot \lambda^x}{x!} &; x \geq 0
\end{cases}$
\end{itemize}
\end{multicols}
$$
X\sim Poisson(x;\lambda)\Rightarrow 
\begin{cases}
E(x)=\mu = \lambda = np \\
V(x)=\sigma^2 = \lambda = np\\
D(x)=\sigma=\sqrt{np}
\end{cases}
$$
\subsection{Distribuciones Continuas}
\subsubsection{Distribución Uniforme o Regular $(U)$}
\begin{multicols}{2}
\begin{itemize}
\item Función de Cuantía \\ \vspace{0.025cm} \\
$f(x)=p(x)=
\begin{cases}
\dfrac{1}{b-a} &; a\leq x \leq b \\
0 &; \text{otro caso}
\end{cases}$
\end{itemize}
\columnbreak
\begin{itemize}
\item Función Acumulada \\ \vspace{0.05cm} \\
$F(x)=
\begin{cases}
0 &; x<a \\
\displaystyle\int_{-\infty}^{x} \dfrac{1}{b-a} dx = \dfrac{x-a}{b-a} &;a \leq x < b \\
1 &; x\geq b
\end{cases}$
\end{itemize}
\end{multicols}
$$
X\sim U(x;a,b)\Rightarrow 
\begin{cases}
E(x)=\mu = \dfrac{a+b}{2} \\ \vspace{0.005cm} \\
V(x)=\sigma^2 = \dfrac{(b-a)^2}{12}\\ \vspace{0.005cm} \\
D(x)=\sigma= \dfrac{(b-a)\sqrt{3}}{6}
\end{cases}
$$
\subsubsection{Distribución Exponencial $(exp)$}
\begin{multicols}{2}
\begin{itemize}
\item Función de Cuantía \\ \vspace{0.025cm} \\
$f(x)=p(x)=
\begin{cases}
\lambda\cdot e^{-\lambda x} &; x\geq 0 \\
0 &; \text{otro caso}
\end{cases}$
\end{itemize}
\columnbreak
\begin{itemize}
\item Función Acumulada \\ \vspace{0.05cm} \\
$F(x)=
\begin{cases}
0 &; x<0 \\
\displaystyle\int_{-\infty}^{x} \lambda\cdot e^{-\lambda x} dt = 1-e^{-\lambda x} &; x \geq 0
\end{cases}$
\end{itemize}
\end{multicols}
$$
X\sim exp(x;\lambda)\Rightarrow 
\begin{cases}
E(x)=\mu = \dfrac{1}{\lambda} \\ \vspace{0.05cm} \\
V(x)=\sigma^2 = \dfrac{1}{\lambda^2}\\ \vspace{0.05cm} \\
D(x)=\sigma= \dfrac{1}{\lambda}
\end{cases}
$$
$\bigstar$ Propiedad Amnésica 
$$P(X>s+t / x>s) = P(X>t)$$
\subsubsection{Distribución Normal $(N)$}
\begin{multicols}{2}
\begin{itemize}
\item Función de Cuantía \\ \vspace{0.025cm} \\
$f(x)=N(x;\mu,\sigma^2)=\dfrac{1}{\sigma \sqrt{2\pi}} e^{-\frac{1}{2} (\frac{x-\mu}{\sigma})^2 } ;x\in\mathbb{R}$
\end{itemize}
\columnbreak
\begin{itemize}
\item Función Acumulada \\ \vspace{0.05cm} \\
$F(x)=
\displaystyle\int_{-\infty}^{x} \dfrac{1}{\sigma \sqrt{2\pi}} e^{-\frac{1}{2} (\frac{t-\mu}{\sigma})^2 } dt
$
\end{itemize}
\end{multicols}
\subsubsection*{Distribución Normal Estándar}
\begin{itemize}
\item Función de Cuantía \\
$$
f(z)=N(z;0,1)=N(0,1)=\dfrac{1}{\sqrt{2\pi}}\cdot e^{-\frac{1}{2}(\frac{x-\mu}{\sigma})^2} dx \hspace{0.5cm} z\in\mathbb{R}
$$
\item Función Acumulada \\
$$
F(z)=P(Z\leq z)=\phi (z)=\displaystyle\int_{-\infty}^{z} \dfrac{1}{\sqrt{2\pi}}\cdot e^{-\frac{1}{2}r} dr
$$
\end{itemize}
\subsubsection*{Transformación}
$$X\sim N(x;\mu,\sigma^2) \Rightarrow z = \dfrac{x-\mu}{\sigma} \sim N(z;0,1) \text{ ó } N(0,1)$$
\noindent$\bigstar$ Manejo de la Tabla:
\begin{enumerate}
\item $P(X<a)=P(X\leq a) = P \Bigg( \dfrac{x-\mu}{\sigma}\leq\dfrac{a-\mu}{\sigma}\Bigg) 
= P\Bigg( z\leq \dfrac{a-\mu}{\sigma}\Bigg) 
=\phi\Bigg( \dfrac{a-\mu}{\sigma} \Bigg)$
\item 
$
P(X>a) =1-P(X\leq a) 
	 =1-\phi\Bigg(\dfrac{a-\mu}{\sigma}\Bigg)
$
\item 
$
P(a\leq X\leq b)= P(X\leq b)-P(X\leq a) 
                = P\Bigg(z\leq \dfrac{b-\mu}{\sigma}\Bigg)-\Bigg(z\leq \dfrac{a-\mu}{\sigma}\Bigg) 
                =\phi\Bigg(\dfrac{b-\mu}{\sigma}\Bigg)-\phi\Bigg(\dfrac{a-\mu}{\sigma}\Bigg)
$
\item 
$
P(x\leq -a) = 1-P(X\leq a)
            = 1-\phi\Bigg( \dfrac{a-\mu}{\sigma}\Bigg)
$
\item 
$P(|X|<a) = P(|X|\leq a) 
         = P(-a\leq X \leq a) 
         = \phi\Bigg(\dfrac{a-\mu}{\sigma}\Bigg)-\phi\Bigg(\dfrac{-a-\mu}{\sigma}\Bigg)$
\item $
P(|x|>a) = 1-P(|x|\leq a) 
	   = 1-P(-a \leq x \leq a) 
	   = 1 - \phi\Bigg(\dfrac{a-\mu}{\sigma}\Bigg)+\phi\Bigg(\dfrac{-a-\mu}{\sigma}\Bigg)$


\end{enumerate}
\subsubsection*{Distribución Normal como aproximación Binomial}
$$\lim_{n\rightarrow\infty} b(x;n,p)\approx N(x;np,npq)\approx N(x;\mu,\sigma^2)$$
$$
P(x_1\leq X\leq x_2)=\displaystyle\sum_{x=x_1}^{x_2} b(x;n,p)\simeq\displaystyle\int_{x_1-\frac{1}{2}}^{x_2+\frac{1}{2}} N(x;np,npq) dx = \displaystyle\int_{z_1}^{z_2} N(z;0,1) dz
$$
Donde:
\begin{itemize}
\item $z_1=\dfrac{(x_1-\frac{1}{2})-np}{\sqrt{npq}}$
\item $z_2=\dfrac{(x_2+\frac{1}{2})-np}{\sqrt{npq}}$
\end{itemize}
\subsubsection{Distribución Chi-Cuadrado $(\chi^2)$}
\begin{itemize}
\item Función de Densidad \\
$$
f(x)=
\begin{cases}
\dfrac{1}{2^{\frac{r}{2}}\Gamma\Big( \dfrac{r}{2} \Big)}\cdot x^{\frac{r}{2}-1} \cdot e^{-\frac{1}{2}x} &; x>0 \\
0 &; \text{otro caso}
\end{cases}
$$
\end{itemize}
$$
X\sim\chi^2(r)\Rightarrow
\begin{cases}
E(x)=\mu=r \\
V(x)=\sigma^2 = 2r \\
D(x)=\sigma=\sqrt{2r}
\end{cases}
$$

\subsubsection{Distribución Fisher-Snedecor $(F)$}
\begin{itemize}
\item Función de Densidad \\
$$
f(z)=
\begin{cases}
\dfrac{\Big(\dfrac{r_1}{r_2}\Big)^{\frac{r_1}{2}}\Gamma\Big(\dfrac{r_1+r_2}{2}\Big) }{\Gamma\Big(\dfrac{r_1}{2}\Big)\Gamma\Big(\dfrac{r_2}{2}\Big)}\cdot \dfrac{x^{\frac{r_1}{2}-1}}{\Big(1+\dfrac{r_1}{r_2}x\Big)^{\frac{r_1+r_2}{2}}} &;x>0 \\
0 &;\text{otro caso}
\end{cases}
$$
\end{itemize}
\subsubsection*{Corolario}
$$
X\sim F(r_1,r_2)\Rightarrow
\begin{cases}
E(x)=\mu=\dfrac{r_2}{r_2-2} & \forall r_2>2 \\\vspace{0.05cm} \\
V(x)=\sigma^2=\dfrac{2r^2(r_1+r_2-2)}{r_2(r_2-2)^2(r_2-4)}
\end{cases}
$$
\noindent$\bigstar$ Manejo de la Tabla:
$$P(X\leq c) = 1-\alpha \text{ ó } P(X\leq F_{1-\alpha}(r_1,r_2))=1-\alpha$$
\subsubsection{Distribución T-Student $(t)$}

\section{Muestreo}
\subsection{Distribuciones de Muestreo}
Algunas distribuciones de Muestreo:
\begin{multicols}{3}
\begin{itemize}
\item $\widehat{\theta}=\dfrac{\displaystyle\sum_{i=1}^{n} x_i}{n}=\overline{x}$
\end{itemize}
\columnbreak
\begin{itemize}
\item $\widehat{\theta}=\dfrac{\displaystyle\sum_{i=1}^{n} (x_i-\overline{x})^2}{n}=S^2$
\end{itemize}
\columnbreak
\begin{itemize}
\item $\widehat{\theta}=\dfrac{\displaystyle\sum_{i=1}^{n} (x_i-\overline{x})^2}{n-1}=\widehat{S}^2$
\end{itemize}
\end{multicols}
\subsection{Estadístico}
\subsubsection{Desigualdad de Chebyshev}
$$
P(|x-\mu|<k\sigma) \geq 1-\dfrac{1}{k^2} \hspace{0.5cm};k\in \mathbb{R^+}
$$
\subsection{Distribución de Muestreo de la diferencia o suma de las medias}
\begin{enumerate}[label=\Roman*)]
  \item $z=\dfrac{(\bar{x}\pm\bar{y})-(\mu_x\pm\mu_y)}{\sqrt{\dfrac{\sigma_{x}^2}{n_1}+\dfrac{\sigma_{y}^2}{n_2}}}$
  \item $t=\dfrac{(\bar{x}\pm\bar{y})-(\mu_x\pm\mu_y)}{\sqrt{\dfrac{(n_1-1)\hat{S}_x^2+(n_2-1)\hat{S}_y^2}{n_1 + n_2 - 2}\left( \dfrac{1}{n_1}+\dfrac{1}{n_2} \right) }}$ \\
  \begin{itemize}
  \item $r = n_1 +n_2 -2$ \textbf{g.l.}
  \end{itemize}
  \item $\sigma_x^2 \simeq S_x^2 \wedge \sigma_y^2 \simeq S_y^2$
\end{enumerate}
\subsection{Distribución de la proporción muestral}
\section{Estimación Estadística}
\begin{center}
 \begin{tabular}{|c|c|}
\hline 
Parámetros & Estadígrafos \\ 
\hline 
$\mu$ & $\bar{x}$ \\ 
$\sigma^2$ & $S^2$ ó $\hat{S}^2$ \\
$p,\pi$ & $\hat{p},\hat{\pi}$\\
\hline 
\end{tabular}
 \end{center} 
\subsection{Estimación Puntual}
\subsubsection{Propiedades}
\begin{itemize}
\item Estimador Insesgado: $E(\hat{\theta}) = \Theta$
\item Estimador Eficiente: 
$$\hat{\theta}_1 \text{ es mas eficiente que } \hat{\theta}_2 \Leftrightarrow V(\hat{\theta}_1) < V(\hat{\theta}_2)$$
\item Estimador Consistente: 
$$
\begin{cases}
\text{\textbf{(i) }} \displaystyle\lim_{n\to\infty} E(\hat{\theta})=0 \\
\text{\textbf{(ii) }} \displaystyle\lim_{n\to\infty} V(\hat{\theta})=0 \\
\end{cases}
$$
\item Estimador Suficiente: $\hat{\theta}$ es un suficiente de $\Theta$ ssi: Aporta tanta información acerca de los parámetros que se estiman a partir de una muestra de $\Theta$.
\end{itemize}
\subsection{Sesgo y Error Cuadrático Medio de un Estimador (ECM)}
\begin{multicols}{2}
\subsubsection*{Sesgo}
\begin{center}
$Sesgo(\hat{\theta})= E(\hat{\theta}) - \theta$\footnote{$Sesgo(\widehat{\theta})=0$, entonces $\widehat{\theta}$ es un estimador incesgado.}
\end{center}
\columnbreak
\subsubsection*{ECM}
\begin{center}
$ECM(\hat{\theta}) = E\big[ (\hat{\theta}-\theta)^2 \big]=V(\hat{\theta}) + \Big[ Sesgo(\hat{\theta})\Big]^2$
\end{center}
\end{multicols}
\subsection{Estimación por Intervalo}
\subsubsection{Estimación por Intervalo de la Media Poblacional}
\begin{enumerate}[label=(\roman*)]
  \item $P\left(\bar{x} - z_{1-\dfrac{\alpha}{2}}\cdot \dfrac{\sigma}{\sqrt{n}}\leq \mu \leq \bar{x} + z_{1-\dfrac{\alpha}{2}}\cdot \dfrac{\sigma}{\sqrt{n}} \right)=1-\alpha$
  \item $P\left(\bar{x} - t_{1-\dfrac{\alpha}{2}}(r)\cdot \dfrac{\widehat{S}}{\sqrt{n}}\leq \mu \leq \bar{x} + t_{1-\dfrac{\alpha}{2}}(r)\cdot \dfrac{\widehat{S}}{\sqrt{n}} \right)=1-\alpha$
\end{enumerate}
  Donde:
\begin{itemize}
\item $r=n-1$ \textbf{g.l.}
\end{itemize}
\subsubsection{Estimación por Intervalo de la diferencia o suma de Medias}
\begin{enumerate}[label=(\roman*)]
  \item $P\left( (\bar{x}\pm\bar{y}) - z_{1-\dfrac{\alpha}{2}}\cdot \sqrt{\dfrac{\sigma_{x}^2}{n_1}+\dfrac{\sigma_{y}^2}{n_2}} \leq \mu_x\pm\mu_y \leq (\bar{x}\pm\bar{y}) + z_{1-\dfrac{\alpha}{2}}\cdot \sqrt{\dfrac{\sigma_{x}^2}{n_1}+\dfrac{\sigma_{y}^2}{n_2}} \right)=1-\alpha$ 
  \item $P\left( (\bar{x}\pm\bar{y})-t_{1-\dfrac{\alpha
  }{2}}(r)\cdot\beta\leq \mu_x\pm\mu_y \leq (\bar{x}\pm\bar{y})+t_{1-\dfrac{\alpha
  }{2}}(r)\cdot\beta\right)=1-\alpha$\vspace{0.5cm}\\
  Donde:
  \begin{itemize}
  \item $\beta = \sqrt{\dfrac{(n_1-1)\hat{S_x}^2+(n_2-1)\hat{S_y}^2}{n_1+n_2-2}\cdot\left(\dfrac{1}{n_1}+\dfrac{1}{n_2}\right)}$
  \item $r=n_1+n_2-2$ \textbf{g.l.}
   \end{itemize}
\end{enumerate}
\subsubsection{Estimación por Intervalo para Proporciones}
\begin{enumerate}[label=(\roman*)]
\item $P\left(\hat{p}-z_{1-\dfrac{\alpha}{2}}\cdot\sqrt{\dfrac{\hat{p}(1-\hat{p})}{n}}\leq p \leq \hat{p}+z_{1-\dfrac{\alpha}{2}}\cdot\sqrt{\dfrac{\hat{p}(1-\hat{p})}{n}}  \right)=1-\alpha$
\item $P\left((\widehat{p_1}\pm\widehat{p_2})-z_{1-\dfrac{\alpha}{2}}\cdot\beta\leq p_1\pm p_2\leq (\widehat{p_1}\pm\widehat{p_2})+z_{1-\dfrac{\alpha}{2}}\cdot\beta\right)=1-\alpha$\\
 Donde:
  \begin{itemize}
  \item $\beta = \sqrt{\dfrac{\hat{p_1}(1-\hat{p_1})}{n_1}+\dfrac{\hat{p_2}(1-\hat{p_2})}{n_2}} $
   \end{itemize}
\end{enumerate}
\subsection{Relación entre el error de Estimación $(E)$ y el riesgo de estimación $(\alpha)$}
$$
E = |\hat{\theta}-\theta| \hspace{1cm} z = \dfrac{\hat{\theta}-\theta}{\sigma_{\hat{\theta}}}
$$
$$
-z_{1-\dfrac{\alpha}{2}} \leq z \leq z_{1-\dfrac{\alpha}{2}} \Leftrightarrow E < z_{1-\dfrac{\alpha}{2}} \cdot \sigma_{\hat{\theta}}
$$
\subsection{Relación entre el error de estimación $(E)$ y el tamaño de la muestra $(n)$}
\subsubsection{En la distribución de la media muestral}
$$
E = |\bar{x}-\mu| \Rightarrow n \geq \left( \dfrac{z_{1-\dfrac{\alpha}{2}}\cdot\sigma}{E}\right)^2$$
\subsubsection{En la distribución de la proporción muestral}
\begin{multicols}{3}
\begin{itemize}
\item $n=\dfrac{z_{1-\dfrac{\alpha}{2}}^2\cdot p\cdot q}{E^2}$
\end{itemize}
Población Infinita
\columnbreak
\begin{itemize}
\item $n=\dfrac{z_{1-\dfrac{\alpha}{2}}^2}{4E^2}$
\end{itemize}
$q = p = 0.5 $
\columnbreak
\begin{itemize}
\item $n=\dfrac{N\cdot z_{1-\dfrac{\alpha}{2}}^2 \cdot p\cdot q}{(N-1)E^2 + z_{1-\dfrac{\alpha}{2}}^2 \cdot p\cdot q}$
\end{itemize}
Población Finita
\end{multicols}
\section{Prueba de Hipótesis}
\begin{multicols}{3}
\begin{itemize}
\item $H_0\geq \\ H_1 <$
\end{itemize}
Cola Inferior
\columnbreak
\begin{itemize}
\item $H_0\leq \\ H_1 >$
\end{itemize}
Cola Superior
\columnbreak
\begin{itemize}
\item $H_0= \\ H_1 \neq $
\end{itemize}
Doble Cola
\end{multicols}
\subsubsection*{Valores Críticos}
\begin{center}
 \begin{tabular}{|c|c|c|c|c|c|}
\hline 
$\alpha$ & 0.10 & 0.05 & 0.01 & 0.005 & 0.002 \\ 
\hline 
Una Cola & $\pm 1.28$ & $\pm 1.64$ & $\pm 2.33$ & $\pm 2.58$& $\pm 2.88$ \\ 
\hline 
Dos Colas & $\pm 1.64$ & $\pm 1.96$ & $\pm 2.58$ & $\pm 2.81$ & $\pm 3.08$\\ 
\hline
\end{tabular}
 \end{center} 
\section{Misceláneo}
\subsection{Tabla: Coeficientes de Confianza o valores críticos $(1-\frac{\alpha}{2})$}
\begin{center}
 \begin{tabular}{|c|c|c|c|c|c|c|c|c|}
\hline 
$1-\alpha$ & 0.9973 & 0.99 & 0.98 & 0.96 & 0.9545 & 0.95 & 0.90 & 0.68 \\ 
\hline 
$100(1-\alpha)\%$ & 99.73 & 99 & 98 & 96 & 95.45 & 95 & 90 & 68 \\ 
\hline 
$z_{1-\frac{\alpha}{2}}$ & 3.00 & 2.58 & 2.33 & 2.05 & 2.00 & 1.96 & 1.64 & 1.00 \\ 
\hline
\end{tabular}
 \end{center} 
\subsection{Interpolación}
$$
\begin{tabular}{|c|c|}
\hline 
$\phi (z)$ & $z$ \\ 
\hline 
$a$ & $x$ \\ 
\hline 
$b$ & $\lambda$ \\ 
\hline 
$c$ & $y$ \\ 
\hline 
\end{tabular} 
\hspace{0.5cm}
\rightarrow 
\hspace{0.5cm}
\dfrac{a-c}{b-c}=\dfrac{x-y}{\lambda-y}
$$
\end{document}