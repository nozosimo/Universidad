\chapter{Estimación Estadística}
La Estimación Estadística es parte de la inferencia estadistica, cuyo objetivo es estimar los parámetros de una población mediante muestras aleatorias provenientes de ellas. Existen básicamente dos formas de estimación de un parámetro poblacional: Estimación Puntual y Estimación por Intervalo.
\section{Estimación Puntual}
Sean $X_1,X_2,\ldots,X_n$ m.a.'s de tamaño $n$, seleccionada de una población, cuya distribución es $f(x,\theta)$ siendo $\theta$ el parámetro. Se denomina \textbf{Estimador Puntual} del parámetro $\theta$ a cualquier estadístico (v.a.) $\widehat{\theta}=H(X_1,X_2,\ldots,X_n)$, cuyo valor numérico (estadígrafo) proporcionará una \textbf{Estimación Puntual} del parametro $\theta$.
\begin{center}
 \begin{tabular}{|c|c|}
\hline 
Parámetros & Estadígrafos \\ 
\hline 
$\mu$ & $\bar{x}$ \\ 
$\sigma^2$ & $S^2$ ó $\hat{S}^2$ \\
$p,\pi$ & $\hat{p},\hat{\pi}$\\
\hline 
\end{tabular}
 \end{center} 
\subsection{Propiedades de los Estimadores Puntuales}
No toda función de la muestra es un buen estimador de parametro. Un buen estimador es aquel que está mas cerca del parametro que se estima. Para que un estimador puntual sea bueno, debe poseer ciertas propiedades como:
\begin{itemize}
\item Insesgadez (Insesgabilidad)
\item Eficiencia
\item Consistencia
\item Suficiencia
\end{itemize}
\subsubsection{Estimador Insesgado}
$\widehat{\Theta}$ es un estimador Insesgado del parametro $\Theta$:
$$E(\widehat{\Theta})=\Theta$$
\subsubsection{Estimador Eficiente}
$\widehat{\Theta}_1$ es un estimador mas eficiente que $\widehat{\Theta}_2$ (ambos insesgados) del parametro $\Theta$ ssi:
$$ V(\widehat{\Theta}_1) < V(\widehat{\Theta}_2) $$
\subsubsection{Estimador Consistente}
$\widehat{\Theta}$ es un estimador consistente del parametro $\Theta$ ssi:
$$
\begin{cases}
\textbf{i)} \displaystyle\lim_{x\to\infty} E(\widehat{\Theta})=0 \\
\textbf{ii)} \displaystyle\lim_{x\to\infty} V(\widehat{\Theta})=0
\end{cases}
$$
\subsubsection{Estimador Suficiente}
$\widehat{\Theta}$ es un estimador suficiente con parametro  $\Theta$ ssi: \\${ }$\\

``$\widehat{\Theta}$ aporta tanta informacion acerca de los parametros que se estiman, tomando una muestra del parametro.''
\subsection{Sesgo y Error Cuadrático Medio de un Estimador (ECM)}
\subsubsection{Sesgo}
Sesgo del estimador $\widehat{\Theta}$:
$$Sesgo(\widehat{\Theta}) =  E(\widehat{\Theta}) - \Theta$$
Si $Sesgo(\widehat{\Theta})=0$, entonces $\widehat{\Theta}$ es un estimador insesgado:
\subsubsection{EMC}
$$ ECM(\Theta) = E[(\widehat{\Theta}-\Theta)^2] = V(\Theta) + (Sesgo(\Theta))^2$$
\section{Estimación por Intervalo}
Consiste en la estimación de un parámetro poblacional mediante la obtención de un intervalo aleatorio llamado \textbf{Intervalo de Confianza} cuyos limites superior e inferior:
$$ L_i \wedge L_s $$
Son funciones de las v.a. observadas que dependen de cierto estimador $\widehat{\Theta}$ parametro $\Theta$ con una probabilidad:
$$ 1-\alpha$$
que representa el nivel o coeficiente de confianza deseado, esto es, probabilidad de que el parámetro esté comprendido:
$$\mathcal{P}(L_i \leq \Theta \leq L_s) = 1-\alpha$$
El objetivo de la estimación por intervalo es obtener, el intervalo:
$$L_i \leq \Theta \leq L_s$$
y se espera que $100(1-\alpha)\%$ de ello, abarque  el parametro de la población $\Theta$.
\subsection{Formulación General de los Intervalos}
Consideremos $z = \dfrac{\widehat{\Theta}-\Theta}{\sigma_\Theta}$ de aquí; se tiene:
\begin{align*}
&\mathcal{P}\left( -z_{1-\dfrac{\sigma}{2}} \leq z \leq  z_{1-\dfrac{\sigma}{2}} \right) = 1-\sigma \\
\Leftrightarrow & \mathcal{P}\left(-z_{1-\dfrac{\sigma}{2}} \leq \dfrac{\widehat{\Theta}-\Theta}{\sigma_\Theta} \leq  z_{1-\dfrac{\sigma}{2}}   \right) = 1-\sigma \\
\Leftrightarrow & \mathcal{P}\left(-z_{1-\dfrac{\sigma}{2}}\cdot\sigma_\Theta \leq \widehat{\Theta}-\Theta \leq  z_{1-\dfrac{\sigma}{2}} \cdot \sigma_\Theta  \right) = 1-\sigma \\ 
\Leftrightarrow & \mathcal{P}\left(-z_{1-\dfrac{\sigma}{2}}\cdot\sigma_\Theta - \widehat{\Theta} \leq -\Theta \leq  z_{1-\dfrac{\sigma}{2}} \cdot \sigma_\Theta -\widehat{\Theta} \right) = 1-\sigma \\
\Leftrightarrow & \mathcal{P}\left( z_{1-\dfrac{\sigma}{2}}\cdot\sigma_\Theta + \widehat{\Theta} \geq \Theta \geq  -z_{1-\dfrac{\sigma}{2}} \cdot \sigma_\Theta +\widehat{\Theta} \right) = 1-\sigma \\
\Leftrightarrow & \mathcal{P}\left( -z_{1-\dfrac{\sigma}{2}}\cdot\sigma_\Theta + \widehat{\Theta} \leq \Theta \leq    z_{1-\dfrac{\sigma}{2}} \cdot \sigma_\Theta +\widehat{\Theta} \right) = 1-\sigma 
\end{align*}
\subsection{Interpretación de Intervalo de Confianza}
Si se selecciona repetidamente 100 veces muestras de tamaño $n$ tendremos 100 intervalos semejantes al estimador $\widehat{\Theta}\pm z_{\pm \dfrac{\alpha}{2}}\cdot \sigma_{\widehat{\Theta}}$ y esperamos que $100(1-\alpha)\%$ incluyan al parametro y $100\alpha\%$ no lo incluirá.

\begin{center}
\begin{tikzpicture}
\begin{axis}[
  no markers, domain=0:8, samples=100,
  axis lines*=left, xlabel=$\widehat{\theta}$, ylabel=$f(\widehat{\theta})$,
  every axis y label/.style={at=(current axis.above origin),anchor=south},
  every axis x label/.style={at=(current axis.right of origin),anchor=west},
  height=5cm, width=12cm,
  xtick=\empty, ytick=\empty,
  enlargelimits=false, clip=false, axis on top,
  grid = major
  ]

  \addplot [fill=red!20, draw=none, domain=0:2.5] {gauss(4,1.5)} \closedcycle;
  \addplot [fill=red!20, draw=none, domain=5.5:8] {gauss(4,1.5)} \closedcycle;
  \addplot [very thick,black!50!black,line width=0.2mm] {gauss(4,1.5)};
  \node[below] at (axis cs:4,0)  {$\theta$}; 
  \node[below] at (axis cs:2.5,0)  {$L_i$}; 
  \node[below] at (axis cs:5.5,0)  {$L_s$}; 
  
  \draw [very thick, dotted,line width=0.2mm]  (axis cs:2.5,0) -- (axis cs:2.5,0.16);
    \draw [very thick, dotted,line width=0.2mm]  (axis cs:5.5,0) -- (axis cs:5.5,0.16);
    \draw [very thick, dotted,line width=0.2mm]  (axis cs:4,0) -- (axis cs:4,0.27);
    
    \draw (2,0.05) node[] {$\dfrac{\alpha}{2}$};
    \draw (6,0.05) node[] {$\dfrac{\alpha}{2}$};
\end{axis}

\end{tikzpicture}
\end{center}
\subsection{Estimación por Intervalo de la media Poblacional}
\begin{enumerate}[label=\textbf{(\Roman*)}]
  \item $\mathcal{P}\left(\bar{x} - z_{1-\dfrac{\alpha}{2}}\cdot \dfrac{\sigma}{\sqrt{n}}\leq \mu \leq \bar{x} + z_{1-\dfrac{\alpha}{2}}\cdot \dfrac{\sigma}{\sqrt{n}} \right)=1-\alpha$\\${ }$\\
  La estadística $z$ se usa en los siguientes casos:
  \begin{enumerate}[label=\textbf{(\roman*)}]
  \item Muestra grande, Varianza Poblacional conocida y Poblacion normal o no.
  \item Muestra pequeña, Varianza Poblacional conocida y población normal.
  \item Muestra grande, Varianza desconocida y poblacion normal o no. 
  \end{enumerate}
  \item $\mathcal{P}\left(\bar{x} - t_{1-\dfrac{\alpha}{2}}(r)\cdot \dfrac{\widehat{S}}{\sqrt{n}}\leq \mu \leq \bar{x} + t_{1-\dfrac{\alpha}{2}}(r)\cdot \dfrac{\widehat{S}}{\sqrt{n}} \right)=1-\alpha$\\
  La estadística $t$ se usa cuando:
  \begin{enumerate}[label=\textbf{(\roman*)}]
  \item %TODO
  \item La varianza poblacional es desconocida.
  \item La poblacion debe ser normal
  \end{enumerate}
\end{enumerate}
Donde: $r = n - 1$ \textbf{g.l.}
\subsection{Estimación por Intervalo de la Diferencia o suma de medias}
\begin{enumerate}[label=\textbf{(\Roman*)}]
  \item $\mathcal{P}\left( (\bar{x}\pm\bar{y}) - z_{1-\dfrac{\alpha}{2}}\cdot \sqrt{\dfrac{\sigma_{x}^2}{n_1}+\dfrac{\sigma_{y}^2}{n_2}} \leq \mu_x\pm\mu_y \leq (\bar{x}\pm\bar{y}) + z_{1-\dfrac{\alpha}{2}}\cdot \sqrt{\dfrac{\sigma_{x}^2}{n_1}+\dfrac{\sigma_{y}^2}{n_2}} \right)=1-\alpha$ \\${ }$\\
  La Estadística $z$ se aplica en los siguientes casos:
  \begin{enumerate}[label=\textbf{(\roman*)}]
  \item Muestras grandes, varianza poblacional conocida y población normal o no.
  \item Muestra pequeña, varianzas poblacionales conocidos y población normal.
  \item Muestra grande, variables poblacionales desconocidos y población normal o no.
  \end{enumerate}
  $$ \sigma_x^2 \simeq S_x^2 \hspace{0.5cm} \wedge \hspace{0.5cm} \sigma_y^2 \simeq S_y^2 $$
  \item $\mathcal{P}\left( (\bar{x}\pm\bar{y})-t_{1-\dfrac{\alpha
  }{2}}(r)\cdot\beta\leq \mu_x\pm\mu_y \leq (\bar{x}\pm\bar{y})+t_{1-\dfrac{\alpha
  }{2}}(r)\cdot\beta\right)=1-\alpha$\vspace{0.5cm}\\${ }$\\
	La Estadística $t$ se usa cuando:  
  \begin{enumerate}[label=\textbf{(\roman*)}]
  \item La muestra pequeña.
  \item Varianzas poblacionales desconocidas.
  \item Poblaciones son normales.
  \end{enumerate}
  Donde:
  \begin{itemize}
  \item $\beta = \sqrt{\dfrac{(n_1-1)\hat{S_x}^2+(n_2-1)\hat{S_y}^2}{n_1+n_2-2}\cdot\left(\dfrac{1}{n_1}+\dfrac{1}{n_2}\right)}$
  \item $r=n_1+n_2-2$ \textbf{g.l.}
   \end{itemize}
\end{enumerate}
\subsection{Estimación por Intervalo para Proporciones}
\begin{enumerate}[label=\textbf{(\Roman*)}]
\item $\mathcal{P}\left(\hat{p}-z_{1-\dfrac{\alpha}{2}}\cdot\sqrt{\dfrac{\hat{p}(1-\hat{p})}{n}}\leq p \leq \hat{p}+z_{1-\dfrac{\alpha}{2}}\cdot\sqrt{\dfrac{\hat{p}(1-\hat{p})}{n}}  \right)=1-\alpha$
\item $\mathcal{P}\left((\widehat{p_1}\pm\widehat{p_2})-z_{1-\dfrac{\alpha}{2}}\cdot\beta\leq p_1\pm p_2\leq (\widehat{p_1}\pm\widehat{p_2})+z_{1-\dfrac{\alpha}{2}}\cdot\beta\right)=1-\alpha$\\
 Donde:
  \begin{itemize}
  \item $\beta = \sqrt{\dfrac{\hat{p_1}(1-\hat{p_1})}{n_1}+\dfrac{\hat{p_2}(1-\hat{p_2})}{n_2}} $
   \end{itemize}
\end{enumerate}
Si alguna de las poblaciones binomiales son finitos se debe incorporar el factor de correción por población finita.
\subsubsection{Tabla: Coeficientes de Confianza o valores críticos $(1-\frac{\alpha}{2})$}
\begin{center}
 \begin{tabular}{|c|c|c|c|c|c|c|c|c|}
\hline 
$1-\alpha$ & 0.9973 & 0.99 & 0.98 & 0.96 & 0.9545 & 0.95 & 0.90 & 0.68 \\ 
\hline 
$100(1-\alpha)\%$ & 99.73 & 99 & 98 & 96 & 95.45 & 95 & 90 & 68 \\ 
\hline 
$z_{1-\frac{\alpha}{2}}$ & 3.00 & 2.58 & 2.33 & 2.05 & 2.00 & 1.96 & 1.64 & 1.00 \\ 
\hline
\end{tabular}
 \end{center} 

\subsection{Relación entre el Error de Estimación y el Riesgo de Estimación}
$$ E=|\widehat{\Theta}-\Theta | \text{ (Estimador - Parámetro)} $$

$$z = \dfrac{\widehat{\Theta}-\Theta}{\sigma_{\widehat{\Theta}}}$$ \\{ }\\
$$ -z_{1-\dfrac{\alpha}{2}} \leq z \leq z_{1-\dfrac{\alpha}{2}} $$
  $$\Updownarrow$$
  $$ -z_{1-\dfrac{\alpha}{2}} \leq \dfrac{\widehat{\theta}-\theta}{\sigma_{\widehat{\theta}}} \leq z_{1-\dfrac{\alpha}{2}} $$
  $$-z_{1-\dfrac{\alpha}{2}}\cdot\sigma_{\widehat{\theta}} \leq {\widehat{\theta}-\theta} \leq z_{1-\dfrac{\alpha}{2}}\cdot\sigma_{\widehat{\theta}}$$
  $$|{\widehat{\theta}-\theta} | < z_{1-\dfrac{\alpha}{2}}\cdot\sigma_{\widehat{\theta}} $$
  $$ E  < z_{1-\dfrac{\alpha}{2}}\cdot\sigma_{\widehat{\theta}}$$
\subsection{Relación entre el Error de Estimación y el tamaño de la Muestra}
\begin{enumerate}[label=\textbf{(\Roman*)}]
  \item En la Distribución de la \textbf{Media Muestral}
  \begin{align*}
  E=|\overline{x}-\mu| \Rightarrow & E\geq z_{1-\dfrac{\alpha}{2}} \sigma_{\overline{x}} \\
  			     \Rightarrow & E\geq z_{1-\dfrac{\alpha}{2}} \dfrac{\sigma}{\sqrt{n}}\\
  			     \Rightarrow & \sqrt{n}\geq  \dfrac{z_{1-\dfrac{\alpha}{2}}\cdot\sigma}{E} \\
  			     \Rightarrow & n\geq  \left(\dfrac{z_{1-\dfrac{\alpha}{2}}\cdot\sigma}{E}\right)^2
  \end{align*}
  \item En la Distribución de la \textbf{Proporción Muestral}
  \begin{multicols}{3}
\begin{itemize}
\item $n=\dfrac{z_{1-\dfrac{\alpha}{2}}^2\cdot p\cdot q}{E^2}$
\end{itemize}
Población Infinita
\columnbreak
\begin{itemize}
\item $n=\dfrac{z_{1-\dfrac{\alpha}{2}}^2}{4E^2}$
\end{itemize}
$q = p = 0.5 $
\columnbreak
\begin{itemize}
\item $n=\dfrac{N\cdot z_{1-\dfrac{\alpha}{2}}^2 \cdot p\cdot q}{(N-1)E^2 + z_{1-\dfrac{\alpha}{2}}^2 \cdot p\cdot q}$
\end{itemize}
Población Finita
\end{multicols}
\end{enumerate}